\chapter{Related Work}
\label{chap:background}
The field of creativity research has been studied for decades, and there are many different approaches to the problem. In this section, we will discuss the different approaches to creativity research, and how they relate to our work. We will also discuss the different approaches to creativity in the context of natural language processing, and how they relate to our work.
% Include background, what previous authors have done in a mostly neutral style. Optimally expecting ~1000-2000 words and 30-40 references mentioned.

\section{Challenge Landscape}
\label{sec:challenge_landscape}
Most of the work going on in our minds as we read a given text is unconscious. We automatically parse characters and tokenize the text into words, sentences, paragraphs, and so on. At the same time, we apply tagging to understand actors (subjects and objects), actions (verbs), setting and situation (adverb), and also try to understand the sense a given word is used in, and then we transform the connotations or the sense of words inside our own little mind representation of the words. We also apply sentiment analysis to understand the emotional state of the text (or speech), and we apply phonetic analysis to understand the pronunciation of the words, as we read them out in our minds, e.g. when reading a book. Note that we have constrained the example of autonomous processes to reading, although these subconscious processes happen regardless of whether we read, write, or speak. Fact of the matter is, language is inherently a complex social construct that takes years to learn, even more to master, and more than a lifetime to perfect. Because it is so expressive and hard to grasp, many rules have been invented and applied to constrain or clearly define the boundaries of the language (e.g. English), so that, within a given language speaker group (e.g. the space of English speakers), the biggest common denominator of people may understand what is being said by the others. The rules may additionally have their own rules and exceptions to the rules. 


Therefore, there are multiple approaches being applied to natural language processing tasks. The more classical one, and the one that has been applied for the larger part of the developments in the field, has been the rule-based method. The approach seeks to use clearly defined rules to parse and understand the linguistic features of the given text. It is a strong approach, as language has been strongly studied for centuries and the aforementioned rules and constraints have already been applied to it. For languages with few changing features or slowly changing features, it performs acceptably well on most NLP tasks, and not far off from human speakers. \note{expand with 1-2 paragraphs and \textbf{references pls}}

Another approach or a subclass of the rule-based approach, is the \textbf{statistical method} \mk{this statement is not bs, right?}. The statistical method seeks to find patterns inside language as a whole. For example, the word ``wind'' may appear both as a noun and a verb -- that is, the meaning of the word may be ambiguous -- but the noun form is much more prevalent. Therefore, in tasks such as part of speech (PoS) tagging, some algorithms prefer to use the most common type of PoS class a given word occurs as, in a sufficiently large corpus of text. We do come back to the PoS tagging example later on. Alternative example of the statistical method being applied would be translation. Previous approaches to machine translation (MTL) included learning frequency of words and phrases occurring together (and how those map to counterparts in the language being translated to). For example:
\begin{quotation}
    Finding Nemo is like finding fish in a school of fish.
\end{quotation}
A naive approach to the translation of this sentence would consider school as its most common (noun) definition - that of place of learning for \textit{humans} and translated the word literally. A more sophisticated approach to translation, applying not just simple rules to translating, would consider the whole phrase ``school of fish'', and would have understood that it refers to a countable form of the word fish (relating to a large number of fish), and therefore translated the phrase as a whole to the target language.

The most current approach to many of the challenging NLP tasks (text summarization, machine translation, speech recognition, etc.) is a machine-learning based one. The motivation is multifold: firstly, most of the work that goes on in our minds as we read a given text is unconscious and automatic, just as we do not have to consciously intend to breathe in order to breathe. In much the same way, we rarely consciously make an effort to understand every part of the text, and many of the details behind understanding language are vague and ambiguous (consider how someone would respond if they are asked to explain their thought process behind parsing a given text). Secondly, more in line with the topic of our research, we do not have a good (objective) way to measure the quality of the work. It is subjective and difficult to measure. Not to mention, behaviour -- and consequently, consciousness -- is something that arises from environment, upbringing, culture, and so on. Yet, value for quality is something that multiple individuals can share -- many people can have a sense of appreciation for a novel they read or a speech they heard (of course, usually for slightly different reasons and perceptions) -- but there tend to be common elements that people widely enjoy seeing and experiencing.

The intuition of machine learning and deep learning is that you can try to replicate the unconscious logical circuitry going on behind the scenes without having a very solid grasp of the exact logic behind it. Therefore, in fields with few or changing rules, such as linguistics, music, and image processing, the machine learning approach tends to find large success, and has even been shown recently to be able to perform very similarly to humans \citep{bubeck2023sparks}. All in all, we cannot ignore the potential for machine learning to be applied to the field of creativity, and we explore this potential in our work.

We, therefore, go into detail on some of the methods we utilize in the project, and the various approaches that have been taken in the past.

\subsection{Part of Speech Tagging}
As we have established, a word may play a different role depending on its position in the sentence, both absolute and relative to the other words. Words that denote objects or persons, we generally call \textbf{nouns}, while words that denote actions (usually active actions, to be more precise), we call \textbf{verbs}. 

\subsection{Word Sense Disambiguation}

\note{both of these can be included as potential metrics}
\subsection{Sentiment Analysis}

\subsection{Named Entity Recognition}

% Maybe not discuss this in general
\subsection{Phonetic Analysis}

\subsection{Natural Language Generation}
\begin{itemize}
    \item top KP sampling
    \item challenges 
\end{itemize}


\section{Creative Measures}
The field of creativity has been broadly studied, initially by psychologists, and more recently by computer scientists. 
Intuitively, the nature of creativity is a subjective matter, and therefore, it is difficult to define. However, there are some commonalities that can be found in creative works. For example, creativity is often associated with novelty, and is often associated with the ability to generate new ideas. \cite{franceschelli_deepcreativity_2022}, for example, determine the three factors of creativity as value, novelty, and surprise, and then explore machine learning approaches to measuring creativity. We agree with them, but decide not to limit ourselves to just these three. However, their contributions provide insights we can use in our work. \mk{did we use it - if we did not, delete this sentence} 
\begin{itemize}
    \item Burstiness of verbs and derived nouns: Patterns of language are sometimes `bursty' \cite{pierrehumbert_burstiness_2012}. This paper presents an analysis of text patterns for domain X. measures include XYZ...
    \item 
\end{itemize}

\section{Tools}
